# tgscan.nf: Usage

## Introduction

#TODO

## Samplesheet input

You will need to create a samplesheet with information about the samples you would like to analyse before running the pipeline. Use this parameter to specify its location. It has to be a comma-separated file with 3 mandatory columns, and a header row as shown in the examples below.

```bash
--input '[path/to/samplesheet.csv]'
```

```csv
sample,fasta,hmmfile
Spp1,path/to/spp1_genome.fa.gz,path/to/my_hmm_collection.hmm
Spp2,path/to/spp2_genome.fa.gz,path/to/my_hmm_collection.hmm
```

| Column                    | Description                                                                                                                      |
| ------------------------- | -------------------------------------------------------------------------------------------------------------------------------- |
| `sample`                  | Custom sample name. Spaces not allowed.                                                                                          |
| `fasta`                   | Full path to genome fasta file. File can be gzipped and allowed extensions include ".fasta", ".fasta.gz", ".fa" or ".fa.gz".     |
| `hmmfile`                 | Full path to hmm file. Can be generated by concatenating multiple hmm files together (`$ cat *.hmm > my_hmm_collection.hmm`).    |


## Parameter specifications

Here we provide guidance regarding some parameter choices.

- `--seq_eval` (`float || null`): Only report targets with a per sequence E-value <= of this value. Given value will be passed as `-E` argument to hmmsearch. Mutually exclusive with `--seq_bitscore`. \[default: `0.001`]
- `--seq_bitscore` (`float || null`): Only report targets with a per sequence bitscore >= of this value. Given value will be passed as `-T` argument to hmmsearch. Mutually exclusive with `--seq_eval`. \[default: `null`]
- `--dom_eval` (`float || null`): For target sequences that sequences that have
  already satisfied the `--seq_eval` or `--seq_bitscore` thresholds, only report
  targets with a per domain E-value <= of this value. Given value will be passed
  as `--domE` argument to hmmsearch. Mutually exclusive with `--dom_bitscore`.
  \[default: `10.0`]
- `--dom_bitscore` (`float || null`): For target sequences that sequences that
  have satisfied the `--seq_eval` or `--seq_bitscore` thresholds, only report
  targets with a per domain bitscore >= of this value. Given value will be
  passed as `--domT` argument to hmmsearch. Mutually exclusive with
  `--dom_eval`. \[default: `null`]
- `--z_seq_evalue` (`float || null`): Set the # of comparasions for E-value calculation. Enables the comparasion of E-values between
  different hmmsearch runs. \[default: `45638612`]
  ([oddly specific number](<https://www.biostars.org/p/430701/>))
- `--z_seq_bitscore` (`float || null`): Set the # of comparasions for bitscore calculation. Enables the comparasion of bitscores between
  different hmmsearch runs. \[default: `45638612`]



## Running the pipeline

The typical command for running the pipeline is as follows:

```bash
nextflow run tgscan.nf --input ./samplesheet.csv --outdir ./results
```

Note that the pipeline will create the following files in your working directory:

```bash
work                # Directory containing the nextflow working files
<OUTDIR>            # Finished results in specified location (defined with --outdir)
.nextflow_log       # Log file from Nextflow
# Other nextflow hidden files, eg. history of pipeline runs and old logs.
```

If you wish to repeatedly use the same parameters for multiple runs, rather than specifying each flag in the command, you can specify these in a params file.

Pipeline settings can be provided in a `yaml` or `json` file via `-params-file <file>`.

> [!WARNING]
> Do not use `-c <file>` to specify parameters as this will result in errors. Custom config files specified with `-c` must only be used for [tuning process resource specifications](https://nf-co.re/docs/usage/configuration#tuning-workflow-resources), other infrastructural tweaks (such as output directories), or module arguments (args).

The above pipeline run specified with a params file in yaml format:

```bash
nextflow run tgscan.nf -params-file params.yaml
```

with:

```yaml title="params.yaml"
input: './samplesheet.csv'
outdir: './results/'
seq_eval: 0.00001
dom_bitscore: 15.0
```

## Core Nextflow arguments

> [!NOTE]
> These options are part of Nextflow and use a _single_ hyphen (pipeline parameters use a double-hyphen)

### `-profile`

Use this parameter to choose a configuration profile. Profiles can give configuration presets for different compute environments.

Several generic profiles are bundled with the pipeline which instruct the pipeline to use software packaged using different methods (Docker, Singularity, Podman, Shifter, Charliecloud, Apptainer, Conda) - see below.

> [!IMPORTANT]
> It is highly recommend the use of Docker or Singularity containers for full pipeline reproducibility.

### `-resume`

Specify this when restarting a pipeline. Nextflow will use cached results from any pipeline steps where the inputs are the same, continuing from where it got to previously. For input to be considered the same, not only the names must be identical but the files' contents as well. For more info about this parameter, see [this blog post](https://www.nextflow.io/blog/2019/demystifying-nextflow-resume.html).

You can also supply a run name to resume a specific run: `-resume [run-name]`. Use the `nextflow log` command to show previous run names.

### `-c`

Specify the path to a specific config file (this is a core Nextflow command). See the [nf-core website documentation](https://nf-co.re/usage/configuration) for more information.
